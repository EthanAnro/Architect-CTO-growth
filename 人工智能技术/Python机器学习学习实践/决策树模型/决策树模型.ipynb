{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8d0ec75",
   "metadata": {},
   "source": [
    "## 决策树模型的基本原理\n",
    "决策树模型的基本原理是通过对一系列问题进行if/else的推导，最终实现相关决策。决策树的概念并不复杂，主要是通过连续的逻辑判断得出最后的结论，其关键在于如何建立这样一棵“树”。\n",
    "\n",
    "### 决策树模型的建树依据\n",
    "决策树模型的建树依据主要用到的是基尼系数的概念。基尼系数（gini）用于计算一个系统中的失序现象，即系统的混乱程度。基尼系数越高，系统的混乱程度就越高，建立决策树模型的目的就是降低系统的混乱程度，从而得到合适的数据分类效果。\n",
    "\n",
    "除了基尼系数，还有另一种衡量系统混乱程度的经典手段——信息熵。\n",
    "\n",
    "基尼系数涉及平方运算，而信息熵涉及相对复杂的对数函数运算，因此，目前决策树模型默认使用基尼系数作为建树依据，运算速度会较快。商业实战中的数据量通常很大，不同情况下的基尼系数或信息熵的计算是人力难以完成的，因此需要利用机器不停地训练来找到最佳的分裂节点。在Python中，可以用Scikit-Learn库（Anaconda自带）来快速建立一个决策树模型。\n",
    "\n",
    "## 决策树模型的代码实现\n",
    "决策树模型既能做分类分析（即预测分类变量值），又能做回归分析（即预测连续变量值），对应的模型分别为分类决策树模型（DecisionTreeClassifier）和回归决策树模型（DecisionTreeRegressor）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a2f2e",
   "metadata": {},
   "source": [
    "### 分类决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4dbc98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "x = [[1,2], [3,4],[5,6],[7,8],[9,10]]   #特征变量\n",
    "model = DecisionTreeClassifier(random_state=0) # 设置随机状态参数random_state为0，这里的0没有特殊含义，可换成其他数字。它是一个种子参数，可使每次运行结果一致\n",
    "model.fit(x, y)  #fit函数训练模型\n",
    "print(model.predict([[5,5]]))  #用predict()函数进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb1ae5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([[5,5], [7,7], [9,9]]))   #预测多数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94c7f95",
   "metadata": {},
   "source": [
    "### 回归决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f078da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "x = [[1,2], [3,4],[5,6],[7,8],[9,10]]   #特征变量\n",
    "y = [1, 2, 3, 4, 5]  #目标变量\n",
    "model = DecisionTreeRegressor(max_depth=2, random_state=0) # 设置决策树最大深度参数max_depth为2，随机状态参数random_state为0\n",
    "model.fit(x, y)\n",
    "print(model.predict([[9,9]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d949512c",
   "metadata": {},
   "source": [
    "在商业实战中，分类决策树模型用得相对较多，不过分类决策树模型和回归决策树模型都很重要，后续将讲到的随机森林模型、AdaBoost模型、GBDT模型、XGBoost与LightGBM模型都是基于决策树模型进行搭建的。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
