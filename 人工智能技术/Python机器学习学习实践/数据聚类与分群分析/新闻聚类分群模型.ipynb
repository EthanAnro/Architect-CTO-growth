{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebbdfea8",
   "metadata": {},
   "source": [
    "# 新闻聚类分群模型\n",
    "\n",
    "新闻种类繁复多样，可以分为财经、体育、科技、娱乐等题材。在本案例中，根据10个关键词从百度新闻爬取962条新闻，且每个关键词对应的新闻条数相近，通过Python编程对每条新闻划分类别，匹配到正确的版面，这实际上就是在对新闻进行聚类分群。\n",
    "\n",
    "## 一、文本数据的读取与处理\n",
    "### 1、读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78279701",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>关键词</th>\n",
       "      <th>标题</th>\n",
       "      <th>网址</th>\n",
       "      <th>来源</th>\n",
       "      <th>时间</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>华能信托</td>\n",
       "      <td>信托公司2019年上半年经营业绩概览</td>\n",
       "      <td>http://www.financialnews.com.cn/jrsb_m/xt/zx/2...</td>\n",
       "      <td>中国金融新闻网</td>\n",
       "      <td>2019年07月23日 00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>华能信托</td>\n",
       "      <td>首单信托型企业ABS获批</td>\n",
       "      <td>http://www.jjckb.cn/2018-10/23/c_137552198.htm</td>\n",
       "      <td>经济参考网</td>\n",
       "      <td>2018年10月23日 12:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>华能信托</td>\n",
       "      <td>华能贵诚信托孙磊:金融科技助力打造开放信托生态</td>\n",
       "      <td>https://baijiahao.baidu.com/s?id=1639276579449...</td>\n",
       "      <td>同花顺财经</td>\n",
       "      <td>2019年07月17日 10:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>华能信托</td>\n",
       "      <td>华能贵诚信托孙磊:金融科技已经成为信托行业重要的基础设施</td>\n",
       "      <td>https://finance.qq.com/a/20190716/007898.htm</td>\n",
       "      <td>腾讯财经</td>\n",
       "      <td>2019年07月16日 18:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>华能信托</td>\n",
       "      <td>格力电器股权转让意向方闭门开会 华能信托赫然在列</td>\n",
       "      <td>https://finance.sina.com.cn/trust/roll/2019-05...</td>\n",
       "      <td>新浪</td>\n",
       "      <td>2019年05月22日 22:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    关键词                            标题  \\\n",
       "0  华能信托            信托公司2019年上半年经营业绩概览   \n",
       "1  华能信托                  首单信托型企业ABS获批   \n",
       "2  华能信托       华能贵诚信托孙磊:金融科技助力打造开放信托生态   \n",
       "3  华能信托  华能贵诚信托孙磊:金融科技已经成为信托行业重要的基础设施   \n",
       "4  华能信托      格力电器股权转让意向方闭门开会 华能信托赫然在列   \n",
       "\n",
       "                                                  网址       来源  \\\n",
       "0  http://www.financialnews.com.cn/jrsb_m/xt/zx/2...  中国金融新闻网   \n",
       "1     http://www.jjckb.cn/2018-10/23/c_137552198.htm    经济参考网   \n",
       "2  https://baijiahao.baidu.com/s?id=1639276579449...    同花顺财经   \n",
       "3       https://finance.qq.com/a/20190716/007898.htm     腾讯财经   \n",
       "4  https://finance.sina.com.cn/trust/roll/2019-05...       新浪   \n",
       "\n",
       "                  时间  \n",
       "0  2019年07月23日 00:00  \n",
       "1  2018年10月23日 12:21  \n",
       "2  2019年07月17日 10:49  \n",
       "3  2019年07月16日 18:53  \n",
       "4  2019年05月22日 22:53  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('datasets/新闻.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6439efed",
   "metadata": {},
   "source": [
    "### 2、中文分词"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cfca7b",
   "metadata": {},
   "source": [
    "> 通过 jieba 库进行中文分词练习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5072daa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我\n",
      "喜欢\n",
      "编写程序\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "word = jieba.cut('我喜欢编写程序')\n",
    "for i in word:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad70192",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "信托公司 2019 年 上半年 经营 业绩 概览\n"
     ]
    }
   ],
   "source": [
    "# 第1条新闻的标题进行分词\n",
    "import jieba\n",
    "word = jieba.cut(df.iloc[0]['标题']) #用cut()函数对第1条新闻的标题进行分词，并将分词结果赋给变量word，其中df.iloc[0]['标题']表示选取第1条新闻的标题（iloc[0]表示选取第1行数据，即第1条新闻的数据，['标题']表示选取列名为“标题”的列）\n",
    "result = ' '.join(word)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbcbc1f",
   "metadata": {},
   "source": [
    "#### 对所有的新闻标题进行分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f50c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [] # 创建一个空列表words来存储每一条新闻标题的分词结果\n",
    "for i, row in df.iterrows(): # 通过for循环遍历整张表格，其中df.iterrows()是pandas库遍历表格每一行的方法，i对应每一行的行号，row对应每一行的内容\n",
    "    word = jieba.cut(row['标题'])\n",
    "    result = ' '.join(word)\n",
    "    words.append(result) # 用append()函数将每一条新闻标题的分词结果添加到words列表中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74352da3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['信托公司 2019 年 上半年 经营 业绩 概览',\n",
       " '首单 信托 型 企业 ABS 获批',\n",
       " '华能 贵 诚信 托孙磊 : 金融 科技 助力 打造 开放 信托 生态',\n",
       " '华能 贵 诚信 托孙磊 : 金融 科技 已经 成为 信托 行业 重要 的 基础设施',\n",
       " '格力电器 股权 转让 意向 方 闭门 开会   华能 信托 赫然 在 列']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 熟悉上述代码后，也可以将其合并成下面的3行代码\n",
    "words = []\n",
    "for i, row in df.iterrows():\n",
    "    words.append(' '.join(jieba.cut(row['标题'])))\n",
    "words[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6232b17",
   "metadata": {},
   "source": [
    "### 3、文本向量化：构造特征变量\n",
    "> 练习：文本向量化基础：建立词频矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3b143e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer # 从Scikit-Learn库中引入CountVectorizer模块\n",
    "test = ['金融 科技 业绩', '华能 信托 业绩'] # 用于演示的新闻标题，共有2条\n",
    "vect = CountVectorizer() # 将CountVectorizer()函数赋给变量vect\n",
    "x= vect.fit_transform(test) # 用fit_transform()函数进行文本向量化转换，并将转换结果赋给变量x\n",
    "x = x.toarray() # 用toarray()函数将x转换为数组\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf49c11",
   "metadata": {},
   "source": [
    "此时2条新闻标题已经变成了由数字0和1组成的2个一维数组，每个数组中各有5个元素。CountVectorizer()函数会先根据空格来识别每一句话中的词语，例如，它能从第1条新闻标题中识别出“金融”“科技”“业绩”这3个词，从第2条新闻标题中识别出“华能”“信托”“业绩”这3个词，这2条标题一共能识别出“金融”“科技”“华能”“信托”“业绩”这5个不同的词。这5个词便构成了这2条新闻标题的词袋，CountVectorizer()函数会自动对词袋中的词进行编号，通过vocabulary_属性便能获取词袋的内容及相应编号，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7d451eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'金融': 4, '科技': 3, '业绩': 0, '华能': 2, '信托': 1}\n"
     ]
    }
   ],
   "source": [
    "words_bag = vect.vocabulary_\n",
    "print(words_bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db0dc8d",
   "metadata": {},
   "source": [
    "如果只想看到词，不想看到编号，可以使用如下代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d72d5aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['业绩', '信托', '华能', '科技', '金融']\n"
     ]
    }
   ],
   "source": [
    "words_bag2 = vect.get_feature_names()\n",
    "print(words_bag2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0325301",
   "metadata": {},
   "source": [
    "构建词频矩阵，表中的数值即为相关标题中对应特征词的出现频次\n",
    "CountVectorizer()函数会自动过滤掉一个字的词，这样会过滤掉“的”“之”等没有重要含义的词，不过同时也会过滤掉“爱”“坑”等可能有重要含义的词，因此，这个特点既是一个优势，也是一个劣势。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34655d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>业绩</th>\n",
       "      <th>信托</th>\n",
       "      <th>华能</th>\n",
       "      <th>科技</th>\n",
       "      <th>金融</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   业绩  信托  华能  科技  金融\n",
       "0   1   0   0   1   1\n",
       "1   1   1   1   0   0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(x, columns=words_bag2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90955650",
   "metadata": {},
   "source": [
    "#### 文本向量化实战：建立词频矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68932259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dayao/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00700</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>08s</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>150</th>\n",
       "      <th>...</th>\n",
       "      <th>黄萍</th>\n",
       "      <th>黄金</th>\n",
       "      <th>黑客</th>\n",
       "      <th>黑灰产</th>\n",
       "      <th>黑金</th>\n",
       "      <th>黑马</th>\n",
       "      <th>鼓手</th>\n",
       "      <th>鼻祖</th>\n",
       "      <th>齐聚</th>\n",
       "      <th>龙风</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00700  03  04  08s  09  10  100  11  12  150  ...  黄萍  黄金  黑客  黑灰产  黑金  黑马  \\\n",
       "0      0   0   0    0   0   0    0   0   0    0  ...   0   0   0    0   0   0   \n",
       "1      0   0   0    0   0   0    0   0   0    0  ...   0   0   0    0   0   0   \n",
       "2      0   0   0    0   0   0    0   0   0    0  ...   0   0   0    0   0   0   \n",
       "3      0   0   0    0   0   0    0   0   0    0  ...   0   0   0    0   0   0   \n",
       "4      0   0   0    0   0   0    0   0   0    0  ...   0   0   0    0   0   0   \n",
       "\n",
       "   鼓手  鼻祖  齐聚  龙风  \n",
       "0   0   0   0   0  \n",
       "1   0   0   0   0  \n",
       "2   0   0   0   0  \n",
       "3   0   0   0   0  \n",
       "4   0   0   0   0  \n",
       "\n",
       "[5 rows x 3402 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将所有的新闻标题进行文本向量化并利用pandas库进行展示\n",
    "from sklearn.feature_extraction.text import CountVectorizer # 从Scikit-Learn库引入CountVectorizer模块\n",
    "import pandas as pd\n",
    "vect = CountVectorizer() # 将CountVectorizer()函数赋给变量vect\n",
    "x = vect.fit_transform(words) # 用fit_transform()函数进行文本向量化处理并赋给变量x\n",
    "x = x.toarray() # 用toarray()函数将X转换为数组形式并重新赋给变量x\n",
    "word_bag3 = vect.get_feature_names() # 从词袋中获取不带编号的词\n",
    "df = pd.DataFrame(x, columns=word_bag3)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dc5843",
   "metadata": {},
   "source": [
    "总结来说，当有n条新闻标题时，先用jieba库对它们进行分词，然后用CountVectorizer()函数提取所有分词中k个不同的词，用这些词构成一个词袋，每个词对应一个编号，即相应的特征，根据原标题中相关词出现的次数来赋值相关特征为i（即相关词出现的次数），这样就完成了文本数值化的工作，接下来就可以进行模型的搭建与使用了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceddf9ca",
   "metadata": {},
   "source": [
    "## 二、模型的搭建与使用\n",
    "\n",
    "### 1、通过KMeans算法进行聚类分群\n",
    "本案例的原始数据是根据10个关键词爬取的新闻。下面先利用KMeans算法搭建模型进行聚类分群，看看它能否将来自10个不同题材的新闻准确地分门别类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "905dd8bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 3, 3, 0, 0, 0, 0, 0, 8, 0, 8, 8, 0, 0, 0, 0, 8, 0, 0, 8, 0,\n",
       "       7, 0, 0, 0, 0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 7, 8, 0, 8, 0, 8,\n",
       "       0, 0, 0, 7, 8, 0, 8, 0, 8, 0, 0, 0, 7, 8, 0, 8, 0, 8, 0, 0, 0, 7,\n",
       "       8, 0, 8, 0, 8, 0, 0, 0, 7, 8, 0, 8, 0, 8, 0, 0, 0, 7, 8, 0, 8, 0,\n",
       "       8, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3,\n",
       "       3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3,\n",
       "       3, 9, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 0, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3,\n",
       "       3, 3, 0, 3, 3, 9, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 0, 3, 3, 3, 3, 2, 0, 0, 2, 2, 0, 2, 2, 2, 0, 0, 0, 2, 0, 2,\n",
       "       2, 2, 0, 2, 5, 5, 2, 0, 2, 2, 2, 5, 5, 0, 2, 0, 2, 0, 0, 2, 0, 0,\n",
       "       2, 5, 2, 2, 5, 5, 2, 0, 0, 0, 0, 2, 2, 2, 2, 0, 5, 2, 2, 0, 2, 2,\n",
       "       2, 2, 5, 2, 5, 2, 2, 2, 5, 2, 2, 0, 2, 2, 2, 2, 0, 0, 5, 2, 0, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 3, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       4, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans  # 引入Scikit-Learn库中的KMeans模型\n",
    "kms = KMeans(n_clusters=10, random_state=123) # 设置KMeans模型的n_clusters参数为10，即将样本聚成10类，并设置random_state参数为123，使得每次运行代码获得的聚类结果保持一致\n",
    "k_data = kms.fit_predict(df) # 用fit_predict()函数将模型拟合训练和聚类结果传递合二为一(等同于先用fit()函数训练模型，再通过labels_属性获取聚类结果的写法)\n",
    "k_data # 其中每个数字代表一个分类，可以看到，KMeans算法将新闻标题分成了10类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19eea506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['阿里巴巴 的 食堂 长 啥 样 ? 上海 网红 美食 杭州 首站 开在 这'\n",
      " '阿里巴巴 朋新宇 : 为何 中台 能 帮 企业 突破 增长 瓶颈 ?'\n",
      " '阿里巴巴 搭 起 数字 鹊桥 : 4000 万 人种 下 情侣 树   600 万人 绑定 淘宝 亲情 号'\n",
      " '阿里巴巴 大 数据 折射 中国式 “ 我爱你 ” : 54% 码商 夫妻店 由 老婆 管帐'\n",
      " '阿里巴巴 合伙人 之一   跟 了 马云 19 年 后   分 了 40 亿给 她'\n",
      " '三年 薪酬 1.2 亿   成 中国 上市公司 CEO 第一   超过 阿里巴巴 张勇'\n",
      " '投资者 提问 : 阿里巴巴 平头 哥 宣布 “ 普惠 芯片 ” 计划 。 即 未来 将 全面 ...'\n",
      " '探秘 阿里巴巴 未来 酒店 健康 空气 之源' '思必驰 与 华为 、 阿里巴巴 等 人工智能 企业 获评 人工智能 重大 创新 工程 ...'\n",
      " '玄武区 白酒 贴牌 定制 选择 和 阿里巴巴 合作 的' '兴化 阿里巴巴 托管 技术'\n",
      " '美国 股指 期货 反弹   阿里巴巴 集团 涨 2.3%' '铜川 阿里巴巴 账号 优化'\n",
      " '美股 全线 高开 , 标普 500 指数 涨 0.7% , 中概 股 反弹 , 阿里巴巴 涨 逾 3%'\n",
      " '中国 盈利 最高 的 公司 , 不是 阿里巴巴 , 也 不是 腾讯 , 第一名 实至名归'\n",
      " '阿里巴巴 成为 申通 第一 大 股东 , “ 快递 女王 ” 离开 , 网友 : 服 了 !'\n",
      " '申通 大 股东 将 全部 股权 出质 给 阿里巴巴' '携手 阿里巴巴   福建 东山 办开 渔节'\n",
      " '中概 股盘 前 走高   阿里巴巴 集团 涨超 2%'\n",
      " '投资者 提问 : 董秘 您好 , 近期 有 媒体 传闻 , 阿里巴巴 要 战略 投资 贵 公司 , ...'\n",
      " '东榜 投资 引入 阿里巴巴 集团 体系 , 加速 东山岛 互联网 + 新 渔港 经济体 进程'\n",
      " '阿里巴巴 的 顶层 “ 秘密组织 ” 成员 过百 ! 马云 退出 后 , 将 进一步 壮大'\n",
      " '阿里巴巴 的 “ 拖油瓶 ” 项目 ? 一年 亏了 200 多亿 , 马云 表示 无所谓'\n",
      " '走进 阿里巴巴 开年 中 总结 大会 , 万事利 集团 未来 要 以 数据 与 智能 驱动 ...'\n",
      " '第二届 阿里巴巴 智能 云上 编程 大赛 暨 智联 招聘 人岗 智能 匹配 挑战赛 ...'\n",
      " '数字化 重构 跨境 贸易 丨 阿里巴巴 国际 站 二十周年 庆典暨 全球战略 商家 ...'\n",
      " '全食 超市 CEO 点评 阿里巴巴 : 未来 5 年 继续 引领 电商 、 云及 支付 市场'\n",
      " '厉害 了 ! 阿里巴巴 点名 沛县 这 2 个 镇 3 个村 ! 还有 … …'\n",
      " '阿里巴巴 或 将 成为 控股 股东 , 但 申通 快递 股价 却 三天 跌 逾 20%'\n",
      " '投资者 提问 : 阿里巴巴 是不是 入股 了 公司 的 子公司 安徽 开开 视界 电子 ...'\n",
      " '中国 最 赚钱 的 公司 , 不是 中国移动 , 也 不是 阿里巴巴 , 那 第一 是 ?'\n",
      " '投资者 提问 : 目前 公司 与 阿里巴巴 的 合作 进展 如何 ?' '中概 股 多数 收跌 , 阿里巴巴 跌 4.53%'\n",
      " '阿里巴巴 终于 吞下 申通 , “ 快递 女王 ” 套现 百亿 离场 , 网友 : 真服了'\n",
      " '「 城事 」 浦东 警方 与 阿里巴巴 协作 , 破 特大 假 “ 戴森 ” 案 →' '阿里巴巴   秘密 成立 核心 团队 经发委'\n",
      " 'Jefferies 对 阿里巴巴 首次 覆盖 评级 为 买入'\n",
      " '阿里巴巴 和 Paytm 成立 游戏 的 公司 计划 再融资 2500 万美金'\n",
      " '阿里巴巴 传 秘密 成立 经发委 , 阿里 系 顶层 秘密组织 强势 增至 百 人'\n",
      " '阿里巴巴 传 秘密 成立 经发委 , 阿里 系 顶层 秘密组织 强势 增至 百 人' '阿里巴巴 回应 秘密 成立 经发委 : 不予置评'\n",
      " '“ 没有 女性 , 就 没有 阿里巴巴 ” , 马云 将 出席 全球 女性 创业者 大会'\n",
      " '阿里巴巴 支付宝 大 出行 板块 用户 达 4 亿 , 腾讯 要 慌 了 吗 ?'\n",
      " '阿里巴巴 成立 经济体 发展 委员会 , 成员 已有   100   人 左右' '阿里巴巴 成立 经济体 发展 委员会'\n",
      " '茵曼成 阿里巴巴 “ 纳税 好友 ” , 向 社会 树立 诚信 榜样'\n",
      " '阿里巴巴 与 腾讯 : 两大 巨头 竞争 升级 , 纷纷 斥 巨资 抢占 这个 新 领域 !'\n",
      " '只是 疏忽 ? 《 亲爱 的 》 收官 翻车 , 阿里巴巴 也 曾 犯过 同样 错误 !'\n",
      " 'FAANG 全线 下跌 ! 美股 小幅 低开 , 阿里巴巴 跌 逾 2%' '美股 小幅 低开 , 阿里巴巴 跌 逾 2%'\n",
      " '阿里巴巴 集团 : 股票 分割 将 于 7 月 30 日 生效 !'\n",
      " '全球 《 财富 》 榜 再次 更新 , 阿里巴巴 腾讯 被 反超 ? 京东 成 最大 黑马 !'\n",
      " '“ 新 基建 ” 迎来 重磅 利好 信号 , 阿里巴巴 提前 撒糖' '阿里巴巴 公益 一行 到 江西 玉山 对 扬帆 计划 项目 学校 考察'\n",
      " '阿里巴巴 国际 站 商品 分层 升级   发布 成长 分' '阿里巴巴 欲 斥资 百亿 追投   申通 快递 实控 人 或 变更 跌停'\n",
      " '获得 申通购 股权 背后   阿里巴巴 快递 棋局 怎么 下 ?' '创始 团队 有意 出让 控股权   阿里巴巴 或成 申通 快递 大 股东'\n",
      " '斥资 99.82 亿元   阿里巴巴 与 申通 快递 签署 购股 选择权 协议'\n",
      " '阿里巴巴 宣布 股票 分割 , 是 为 回港 上市 做 准备 吗 ?'\n",
      " '阿里巴巴 再 拿下 申通 快递 购 股权   未来 或成 后者 实控 人'\n",
      " '47 亿 入股 后 欲 追 投 百亿   阿里巴巴 有望 入主 申通 快递' '再 砸 百亿 ! 阿里巴巴 或 拿下 申通 快递 控股权'\n",
      " '申通 快递 控股 股东 与 阿里巴巴 签署 购股 选择权 协议'\n",
      " '解密 寻乌 脱贫 密码 613854   阿里巴巴 发布 2019 脱贫 半年 报告'\n",
      " '阿里巴巴 脱贫 基金 成立 一年 半 , 贫困县 土货 销售 超 千亿元' '阿里巴巴 为 小区 居民 集体 颁发 正 能量 奖金 1 万元'\n",
      " '阿里巴巴 股份 拆细 今晚 美股 开市 前 生效' '阿里巴巴 将 帮助 Salesforce 在 中国 市场 展开 销售'\n",
      " '都 讲 数据 中 台 , 听 “ 鼻祖 ” 阿里巴巴 正本清源' '阿里巴巴 “ 夜 经济 ” 数据 : 夜宵 火爆   骑手 忙碌'\n",
      " '阿里巴巴 升级 服务 数字 政府 战略 : 已 覆盖 442 城   服务 9 亿人'\n",
      " '细数 阿里巴巴 从 电商 平台 到 上市 孵化器 的 升级 之 路 ( 1 )' '阿里巴巴 推出 人工智能 芯片 “ 玄铁 ”'\n",
      " '这 100 万张 订单 背后 , 阿里巴巴 引发 中国 企业 的 采购 革命'\n",
      " '海思 一封信 后 , 阿里巴巴 和 苹果 围着 芯片 转 , ARM 下场 难看'\n",
      " '与 阿里巴巴 合作 这 一年 , 星巴克 股价 翻倍 , 市值 增长 600 亿美金'\n",
      " '家装 建材 领域 “ 阿里巴巴 ” ! 这家 公司 从 “ 外行 ” 到 行业 前 三 , 营销 ...'\n",
      " '阿里巴巴 聚 划算 为啥 汇聚 甘肃 ? 将 带来 怎样 改变 ?'\n",
      " '阿里巴巴 谈新 合作 ! 马云买 当地 冰棍 , 有 谁 注意 到 他 的 付款 方式 ?'\n",
      " '阿里巴巴 亮出 “ 倚天剑 ”   砍 低 芯片 研发 门槛'\n",
      " '马云 价值 3 亿 的 私人 飞机 费用 全 由 阿里巴巴 报销 , 每年 多省 6000 万'\n",
      " '“ 不飞 则 已 , 一飞冲天 ” , 自 华为 之后 , 阿里巴巴 终在 这 领域 出手 了'\n",
      " '深耕 半导体 行业 ! 阿里巴巴 ( BABA . US ) 成功 研发 “ 阿里 ” 人工智能 芯片'\n",
      " '阿里巴巴 推出 首款 芯片   瞄准 物 联网 领域'\n",
      " '阿里巴巴 平头 哥 首发 玄铁 910 , 国产 芯片 的 大门 是否 已经 被 掀开 ?'\n",
      " '蜜瓜 换 树苗 ! 甘肃 民勤 与 阿里巴巴 合作 开启 “ 助农 + 治沙 ” 模式'\n",
      " '阿里巴巴 开放 数据 化 运营 能力   服务 数字 政府 2.0 建设'\n",
      " '华为 收入 超过 阿里巴巴 腾讯 总和   任正非 : 还是 赚 多 了'\n",
      " '出海 记 | 迎战 亚马逊 , 阿里巴巴 向 美国 商户 “ 敞开 B2B 大门 ”'\n",
      " '阿里巴巴 宣布 , 向 美国 卖家 开放 阿里巴巴 平台 , 年费 竟然 是 2400 美元'\n",
      " '马云 承诺 的 “ 100 万个 工作岗位 ” 来 了 ! 阿里巴巴 平台 首次 向 美国 商户 ...'\n",
      " '阿里巴巴 点亮 夜 经济 : 夜间 网购 消费 占 比 36%' '乌镇 牵手 阿里巴巴 , 打造 智慧 美丽 江南水乡'\n",
      " '美国公司 即将 入驻 阿里巴巴 平台'\n",
      " '现任 员工 遭 特斯拉 起诉   |   那个 被 富士康 、 阿里巴巴 领投 的 小鹏 汽车 ...'\n",
      " '阿里巴巴 或 下半年 香港 上市 三大 问题 解读' '腾讯 、 阿里巴巴 、 京东 … … 等 名字 的 由 来 , 你 知道 哪些 ?'\n",
      " '从 Google 、 阿里巴巴 、 腾讯   ( GAT )   巨额 收购案 看 「 巨头 并购 战略 」']\n"
     ]
    }
   ],
   "source": [
    "# 打印分类为1的数据查看该分类中的新闻标题\n",
    "import numpy as np\n",
    "words_ary = np.array(words)\n",
    "print(words_ary[k_data == 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2d85d0",
   "metadata": {},
   "source": [
    "## 三、模型优化"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
