{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34269cbe-18ce-434c-a8be-79a8709d982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef43c064-71ca-455b-9b18-bda489f6d264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5890fd33-b245-41e0-ac32-a76cbf4bb4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99b7b8dd-72de-4ae7-85f2-0f1f3addb52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6e9e009-4838-4fbc-baa7-ce688804ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7ac6187-a3f4-48f4-ab44-2592d077064f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 15:35:39.994922: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dac33094-b39a-4d6a-8ca3-b2d3e90b870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cffe0aab-8b7f-41f9-9c55-587715e7a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "953fedca-a439-478b-8229-4be763d8854f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 0.5139 - accuracy: 0.8558\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2359 - accuracy: 0.9309\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1629 - accuracy: 0.9524\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1231 - accuracy: 0.9624\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0925 - accuracy: 0.9729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc8085b0220>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(test_images, test_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e75fe113-9bb9-4f3f-8742-c84192cbc8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.3136953e-04, 4.0365930e-07, 1.0507028e-03, 1.4687653e-02,\n",
       "       6.9492160e-08, 3.4069986e-04, 2.1134559e-07, 9.8289770e-01,\n",
       "       5.7999283e-04, 2.1131003e-04], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digit = test_images[0:10]\n",
    "preditions = model.predict(test_digit)\n",
    "preditions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "049447e3-399d-4d27-a8c0-f745d3f96b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preditions[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ac35db5-b86d-476d-bc7d-340970725c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9828977"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preditions[0][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08a12d03-b50f-4474-b4f2-7e53c2240487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8589f59a-759e-4af4-81b1-6c03b5380675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1122 - accuracy: 0.9641\n",
      "test_acc:0.9641000032424927\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"test_acc:{test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
